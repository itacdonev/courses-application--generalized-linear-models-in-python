---
title: Insert title here
key: 65f818a323555163f8ee44d12e7c3566

---
## Why Generalized Linear Models?

```yaml
type: "TitleSlide"
key: "d7295e1d38"
```

`@lower_third`

name: Ita Cirovic Donev
title: Instructor


`@script`



---
## Review of Linear Models

```yaml
type: "TwoColumns"
key: "a98b8ad71d"
```

`@part1`
**Simple linear model**  

$\normalsize{y = \beta_0 + \beta_1x_1 + \epsilon}$

**General linear model**  
(classical GLM)  

$\normalsize{y = \beta_0 + \beta_1x_1 + ... + \beta_px_p + \epsilon}$

&nbsp;

Goal   

$\normalsize{\mu = E[y|X] = \beta_0 + \beta_1x_1 + ... + \beta_px_p}$


`@part2`
Assumptions
- linear in parameters; $E[y|X]=X\beta$
- errors: independent and normally distributed
- constant variance

What if ... ?   
- the response is not continuous, but for example binary or count
- variance of $y$ depends on the mean


`@script`
To answer these questions, let's consider an example.


---
## Motivating Example

```yaml
type: "TwoColumns"
key: "e78ff4a7ea"
```

`@part1`
Example: Default Risk
- response is binary 1(Default), 0(not default)
- explanatory variables: financial statements

- Fit a linear probability model
- $E[y]=P(y=1)=p$


`@part2`
plot the data


`@script`



---
## Motivating example - the LM model

```yaml
type: "TwoColumns"
key: "7de2d1846e"
```

`@part1`
```python
formula = 'switch ~ dist100'
family = sm.families.Gaussian()

smf.glm(formula = formula, 
        data = wells, 
        family = family).fit()
```
Conclusion:
- violates restriction that $0 \le p \le 1$
- normality violation: distribution  of $y$ is highly skewed when $p$ is close to 0 or 1
- variance of $y$ depends on the mean value


`@part2`
$y = 0.6484 - 0.1515*distance$
![](http://assets.datacamp.com/production/repositories/3864/datasets/e8b20e1711d72172cf07865ef3f479f2f6200e27/Ch1_L1_Scatter_plot_LM.png)


`@script`



---
## Motivating example - A correct model (GLM)

```yaml
type: "TwoColumns"
key: "5af22ba493"
```

`@part1`
```
sm.GLM(family=Binomial())
```
- Correct model formulation
- predictions are bounded by (0,1)
Conclusion:
- take into account how the response variable is measured


`@part2`
$y = 0.606 - 0.6219*distance$
![](http://assets.datacamp.com/production/repositories/3864/datasets/645b498855fb8d2d81ee2c66662a6f4df6946961/Ch1_L1_Scatter_plot_GLM.png)


`@script`



---
## Types of Response Variables

```yaml
type: "FullSlide"
key: "ea23bd526b"
disable_transition: true
```

`@part1`
- explanatory variables: categorical, continuous
- responses are independent random variables

| Response    	| Example                                     	| Method                           	|
|-------------	|:-------------------------------------------:	|:---------------------------------:|
| Continuous  	| `sale price`                                  | Multiple regression             	| 
| $\color{blue}{\text{Binary}}$      	| `True, False`          | $\color{blue}{\text{Logistic Regression}}$              	|
| $\color{blue}{\text{Counts}}$      	| `5, 7, 12, 4` votes          | $\color{blue}{\text{Poisson regression}}$               	|
| Nominal 	    | `red, green, blue` 	                        | Multinominal logistic regression 	|
| Ordinal     	| `[1-10),[10-20),[>20)`                        | Ordinal logistic regression      	|


`@script`
Now that we have seen how the GLMs apply in situations where the main assumptions of the linear model are not satisfied, let's examine further in which situations we can apply the GLMs.


---
## Let's practice!

```yaml
type: "FinalSlide"
key: "72f692d178"
```

`@script`



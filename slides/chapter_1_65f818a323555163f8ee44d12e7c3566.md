---
title: Insert title here
key: 65f818a323555163f8ee44d12e7c3566

---
## Why Generalized Linear Models?

```yaml
type: "TitleSlide"
key: "d7295e1d38"
```

`@lower_third`

name: Ita Cirovic Donev
title: 


`@script`
> Hi, my name is Ita and I welcome you to this course on Generalized Linear Models in Python. Generalized linear models or GLMs for short provide a versatile framework for statistical modeling of data and are used often to solve real world problems. We will examine several of such problems in lessons to come. So stay tuned!


---
## Introduction

```yaml
type: "FullSlide"
key: "284a1d46df"
```

`@part1`
- Motivation for GLM {{1}}
- Building blocks of GLM {{2}}
- Build knowledge on practical examples using Poisson and logistic regression{{3}}

Objectives: {{4}}
- understand how GLM works {{5}}
- formulate and implement a GLM in Python {{6}} 
- interpret the model results {{7}}
- make prediction {{8}}


`@script`
- We will begin the course by motivating the need for GLMs with the review of linear models and how we arrive at the generalized term in the GLM name. 

- Furthermore, we will define the components of the GLM and how to implement them in Python. 
For the rest of the course we will focus on learning the statistical aspects of fitting the model, understanding and analyzing the output and making predictions, by examining various data sets. For this we will use Poisson and logistic regression. By the end of the course you will have both a theoretical understanding and the working knowledge of how to implement a GLM in practice. 

- So to sum up, our main objectives for the course are to 
- understand how GLM  works 
- be able to formulate and implemented a GLM in Python, 
- interpret the model results and finally, 
- learn how to use fitted model to make predictions on new data.


---
## Review of Linear Models

```yaml
type: "FullSlide"
key: "7b85aab958"
```

`@part1`
**Simple linear model**  {{0}}

$\normalsize{y = \beta_0 + \beta_1x_1 + \epsilon}$ {{0}}


`@script`



---
## Review of Linear Models

```yaml
type: "TwoColumns"
key: "69bb78300c"
disable_transition: true
```

`@part1`
**Simple linear model** 

$\normalsize{\color{red}y = \beta_0 + \beta_1x_1 + \epsilon}$


`@part2`
$y$ - response variable


`@script`



---
## Review of Linear Models

```yaml
type: "TwoColumns"
key: "0b1e4f0dbf"
disable_transition: true
```

`@part1`
**Simple linear model** 

$\normalsize{y = \beta_0 + \beta_1\color{red}{x_1} + \epsilon}$


`@part2`
$y$ - response variable
$x$ - explanatory variable


`@script`



---
## Review of Linear Models

```yaml
type: "TwoColumns"
key: "5587486595"
disable_transition: true
```

`@part1`
**Simple linear model** 

$\normalsize{y = \color{red}{\beta_0} + \color{red}{\beta_1}x_1 + \epsilon}$


`@part2`
$y$ - response variable
$x$ - explanatory variable  
$\beta$ - model parameters  
$\beta_0$ - intercept  
$\beta_1$ - slope


`@script`



---
## Review of Linear Models

```yaml
type: "TwoColumns"
key: "73897a6a17"
disable_transition: true
```

`@part1`
**Simple linear model** 

$\normalsize{y = \beta_0 + \beta_1x_1 + \color{red}\epsilon}$


`@part2`
$y$ - response variable
$x$ - explanatory variable  
$\beta$ - model parameters  
$\beta_0$ - intercept  
$\beta_1$ - slope  
$\epsilon$ - random error


`@script`



---
## Review of Linear Models

```yaml
type: "TwoColumns"
key: "8ce5763dc6"
disable_transition: true
```

`@part1`
**Simple linear model** 

$\normalsize{y = \beta_0 + \beta_1x_1 + \epsilon}$ 

&nbsp;

**General linear model**  
(classical GLM)  

$\normalsize{y = \beta_0 + \beta_1x_1 + ... + \beta_px_p + \epsilon}$


`@part2`
$y$ - response variable
$x$ - explanatory variable  
$\beta$ - model parameters  
$\beta_0$ - intercept  
$\beta_1$ - slope  
$\epsilon$ - random error


`@script`



---
## Review of Linear Models

```yaml
type: "TwoColumns"
key: "bc24f029fc"
```

`@part1`
Want to model

$\normalsize{E[y|X] = \mu}$

$\normalsize{ \mu = \beta_0 + \beta_1x_1 + ... + \beta_px_p}$


`@part2`



`@script`
> One of the main goals of regression is to predict Y from the explanatory variables using the relationship as the following. Or in other words we model the information of how much the response variable changes on average for a unit increase in the explanatory variable.


---
## Review of Linear Models

```yaml
type: "TwoColumns"
key: "b9da57178e"
disable_transition: true
```

`@part1`
Want to model

$\normalsize{E[\color{blue}{y|X}] = \mu}$

$\normalsize{ \mu = \beta_0 + \beta_1x_1 + ... + \beta_px_p}$


`@part2`



`@script`
> Note that we write the expectation as y conditional on x due to the fact that the inferences about the relationship of y and x assume knowledge of x.


---
## Review of Linear Models

```yaml
type: "TwoColumns"
key: "cbed00212c"
```

`@part1`
Want to model

$\normalsize{E[y|X] = \mu}$ 

$\normalsize{ \mu = \beta_0 + \beta_1x_1 + ... + \beta_px_p}$


`@part2`
**Assumptions** 
- linear in parameters {{2}}
- errors: independent and normally distributed $N(0,\sigma^2)$ {{3}}
- constant variance (homoscedasticity)  
$Var(y_i) = \sigma^2$ {{4}}


`@script`



---
## Review of Linear Models

```yaml
type: "FullSlide"
key: "115cd470fb"
```

`@part1`
**WHAT IF ... ?**  
- our measurements of the response are not continuous, but for example binary or count {{1}}
- the variance of $y$ depends on the mean {{2}}


`@script`
> Taking into consideration all of the information that we just reviewed, several what if questions can arise,
> first and foremost being, what if my data is not continuous. With all the increased capacities in data measurements we know there exist other types of response variables.
> or what if we dont have constant variance, but rather the variance depends on the mean.  
To illustrate the problem let's consider an example.


---
## Motivating Example - Data

```yaml
type: "FullSlide"
key: "55ff39cc92"
```

`@part1`
- Contamination of ground water with arsenic in Bangladesh
- dataset `wells`
- 3020 observations  
- model the decision on switching wells 

|Variables|Name|Description|
|:-|-|:-|
|Response|`switch`|1 if change of water source occurred; 0 otherwise|
|Explanatory|`arsenic`| The level of arsenic contamination in the well|
|Explanatory|`distance`| Distance to the closest known safe well|
|Explanatory|`education`|Years of education of the head of the household|


`@script`
> For this example we will use a dataset on the contamination of ground water with arsenic in Bangladesh. According to the world health organization, the contamination of groundwater by arsenic in Bangladesh is the largest poisoning of a population in history, with millions of people exposed. Exposure to arsenic increases the risk of cancer and other diseases.
> Our dataset wells, 
> consists of 3020 observations
> using this dataset we want to model the decision on switching the current well that the household uses.
> The dataset consists of a response variable switch, which measures whether the source of water has changed or not from the original source, arsenic is the measured level of arsenic contamination in the well and education denotes number of years of education of the head of the household.


---
## Motivating example - the LM model

```yaml
type: "FullSlide"
key: "c497ddb85d"
```

`@part1`
```python
formula = 'switch ~ arsenic' 
``` {{1}}
```python
family = sm.families.Gaussian() 
``` {{3}}
```py
smf.glm(formula = formula, data = wells, family = family).fit()
``` {{4}}

![](http://assets.datacamp.com/production/repositories/3864/datasets/3ef6d3d112099677e1ca9fb09c9961cf2b1de7c9/Ch1_L1_Scatter_plot_arsenic.png)
{{2}}


`@script`
> First we fit a linear model where switch is predicted by arsenic. 
> Keep in mind that our response varible is binary and not continuous, as can be seen from the figure.
> To model the linear model we define a Gaussian distribution for the response.
> and use the GLM function from the statsmodels library to fit the model. The details of the fit function we will cover in later videos, but for now please note that we need to specify the functional form of the model, distribution of the data and the dataframe where the data is stored.


---
## Motivating example - the LM model

```yaml
type: "FullSlide"
key: "551e61472a"
disable_transition: true
```

`@part1`
```python
formula = 'switch ~ arsenic' 

family = sm.families.Gaussian() 

smf.glm(formula = formula, data = wells, family = family).fit()
```
![](http://assets.datacamp.com/production/repositories/3864/datasets/de114467b003fea04daa83aae23dce73b4d1bade/Ch1_L1_Scatter_plot_LM_arsenic_basic.png)


`@script`
> We obtained the linear fit denoted in red line. We can see something is not OK, as the function goes beyond the range of the possible values 0 and 1.


---
## Motivating example - the LM model

```yaml
type: "FullSlide"
key: "9a7702ce6a"
disable_transition: true
```

`@part1`
```python
formula = 'switch ~ arsenic'

family = sm.families.Gaussian()

smf.glm(formula = formula, data = wells, family = family).fit()
``` 

![](http://assets.datacamp.com/production/repositories/3864/datasets/4ee031be36efd84878e82ca015eaf4d2160217ce/Ch1_L1_Scatter_plot_LM_arsenic.png)


`@script`
> Let's say we take arsenic level to be equal to 8. This will gives us a probability of switching at 1.1 which is clearly not correct.


---
## Motivating example - the LM model

```yaml
type: "FullSlide"
key: "4cc5f907b4"
```

`@part1`
Conclusion: 
- violates restriction that $0 \le p \le 1$
- distribution  of $y$ is highly skewed when $p$ is close to 0 or 1 - not Gaussian
- variance of $y$ depends on the mean value


`@script`
> As we saw there is a clear violation of the range of probability values
> Given the binary response variable the distribution function is not gaussian, and 
> the variance of Y depends on the mean value.


---
## Motivating example - A correct model (GLM)

```yaml
type: "FullSlide"
key: "387f3c5591"
```

`@part1`
```python
formula = 'switch ~ arsenic' 
``` {{1}}
```python
family = sm.families.Binomial() 
``` {{2}}
```py
smf.glm(formula = formula, data = wells, family = family).fit()
``` {{3}}

![](http://assets.datacamp.com/production/repositories/3864/datasets/3ef6d3d112099677e1ca9fb09c9961cf2b1de7c9/Ch1_L1_Scatter_plot_arsenic.png)
{{1}}


`@script`
> Now using the same function form setting, let's change the distribution function from Gaussian to Binomial, since we have binary response and fit the model.
>


---
## Motivating example - A correct model (GLM)

```yaml
type: "FullSlide"
key: "33c3df5544"
disable_transition: true
```

`@part1`
```python
formula = 'switch ~ arsenic' 

family = sm.families.Binomial() 

smf.glm(formula = formula, data = wells, family = family).fit()
``` 

![](http://assets.datacamp.com/production/repositories/3864/datasets/846288f2ee857a9bdf6681e001d701ce6981487b/Ch1_L1_Scatter_plot_GLM_arsenic.png)


`@script`
> The fit looks much better now restricting the range to 0 and 1.


---
## Motivating example - A correct model (GLM)

```yaml
type: "FullSlide"
key: "392587dd68"
```

`@part1`
Conclusion:
- Correct model formulation {{1}}
- Predictions are bounded by (0,1) {{2}}

What changed? {{4}}
- Specifying the Binomial distribution for the response {{5}}
- Introducing the function g (*link function*) which relates $E[y]$ to the linear combination {{6}}

$$\normalsize{E[y]= \beta_0 + \beta_1x_1 + ... + \beta_px_p}$$ {{6}}

$$\normalsize{\color{red}{g}(E[y]) = \beta_0 + \beta_1x_1 + ... + \beta_px_p}$$
{{6}}


`@script`
> Now we can conclude that we have the correct model formulation, where
> the predictions are bounded by 0 and 1
> The important note to take from there is that we need to take into account how our data is measured and choose the appropriate distribution to model it.

> Let's recap and see what changed?
> First we specified the distrobution for the response variable to be Binomial given that our rsponse variable switch is binary. But is this enough? Not quite. 
> We still need to transform the mean of Y so that it is linearly related to X. For this we use the function g, also called the link function, which we will further discuss later on. Note that we didn't have to specify it when fitting the model since the default link function for the binomial distribution is the logit.


---
## Types of Response Variables

```yaml
type: "FullSlide"
key: "f3ef0a4fe2"
```

`@part1`
- explanatory variables: categorical, continuous {{1}}

| Response    	| Example                                     	| Method                           	|
|-------------	|:-------------------------------------------:	|:---------------------------------:|
| Continuous  	| `sale price`                                  | Multiple regression             	| 
{{2}}


`@script`



---
## Types of Response Variables

```yaml
type: "FullSlide"
key: "0aa0fd5995"
disable_transition: true
```

`@part1`
- explanatory variables: categorical, continuous

| Response    	| Example                                     	| Method                           	|
|-------------	|:-------------------------------------------:	|:---------------------------------:|
| Continuous  	| `sale price`                                  | Multiple regression             	| 
| Binary      	| `True, False`                         	    | Logistic regression              	|


`@script`



---
## Types of Response Variables

```yaml
type: "FullSlide"
key: "a876d49eb8"
disable_transition: true
```

`@part1`
- explanatory variables: categorical, continuous

| Response    	| Example                                     	| Method                           	|
|-------------	|:-------------------------------------------:	|:---------------------------------:|
| Continuous  	| `sale price`                                  | Multiple regression             	| 
| Binary      	| `True, False`                         	    | Logistic regression              	|
| Counts      	| `5, 7, 12, 4` votes                                 | Poisson regression               	|


`@script`



---
## Types of Response Variables

```yaml
type: "FullSlide"
key: "b139b03d68"
disable_transition: true
```

`@part1`
- explanatory variables: categorical, continuous

| Response    	| Example                                     	| Method                           	|
|-------------	|:-------------------------------------------:	|:---------------------------------:|
| Continuous  	| `sale price`                                  | Multiple regression             	| 
| Binary      	| `True, False`                         	    | Logistic regression              	|
| Counts      	| `5, 7, 12, 4` votes                                 | Poisson regression               	|
| Nominal 	    | `red, green, blue` 	                        | Multinominal logistic regression 	|


`@script`



---
## Types of Response Variables

```yaml
type: "FullSlide"
key: "54df08102b"
disable_transition: true
```

`@part1`
- explanatory variables: categorical, continuous

| Response    	| Example                                     	| Method                           	|
|-------------	|:-------------------------------------------:	|:---------------------------------:|
| Continuous  	| `sale price`                                  | Multiple regression             	| 
| Binary      	| `True, False`                         	    | Logistic regression              	|
| Counts      	| `5, 7, 12, 4` votes                                 | Poisson regression               	|
| Nominal 	    | `red, green, blue` 	                        | Multinominal logistic regression 	|
| Ordinal     	| `[1-10),[10-20),[>20)`                        | Ordinal logistic regression      	|


`@script`



---
## Types of Response Variables

```yaml
type: "FullSlide"
key: "ea23bd526b"
disable_transition: true
```

`@part1`
- explanatory variables: categorical, continuous

| Response    	| Example                                     	| Method                           	|
|-------------	|:-------------------------------------------:	|:---------------------------------:|
| Continuous  	| `sale price`                                  | Multiple regression             	| 
| $\color{blue}{\text{Binary}}$      	| `True, False`          | $\color{blue}{\text{Logistic Regression}}$              	|
| $\color{blue}{\text{Counts}}$      	| `5, 7, 12, 4` votes          | $\color{blue}{\text{Poisson regression}}$               	|
| Nominal 	    | `red, green, blue` 	                        | Multinominal logistic regression 	|
| Ordinal     	| `[1-10),[10-20),[>20)`                        | Ordinal logistic regression      	|


`@script`
Now that we have seen how the GLMs apply in situations where the main assumptions of the linear model are not satisfied, let's examine further in which situations we can apply the GLMs.


---
## Let's practice!

```yaml
type: "FinalSlide"
key: "72f692d178"
```

`@script`


